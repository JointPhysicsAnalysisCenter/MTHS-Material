{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# basic setup of the notebook\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "from iminuit.util import describe\n",
    "from typing import Annotated\n",
    "\n",
    "# we also need a cost function to fit and import the LeastSquares function\n",
    "from iminuit.cost import LeastSquares\n",
    "\n",
    "# display iminuit version\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Importing fixed params for analysis\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------  \n",
    "total_size_lat = 32\n",
    "measured_T     = 16\n",
    "xi             = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Read raw data and prepare accordingly\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "data=[]\n",
    "data.append(np.genfromtxt('correlators/L{}_xi{}.dat'.format(total_size_lat,xi))[:,1])\n",
    "data=np.array(data[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, store the data in a convenient format for the fits\n",
    "\n",
    "totaltraj=int(len(data)/measured_T)            # Number of montecarlo samples\n",
    "\n",
    "Gc=np.zeros((int(totaltraj),measured_T))       # Storing the data\n",
    "for i in range(int(totaltraj)):\n",
    "    Gc[[i]]=data[range(i*measured_T,(i+1)*measured_T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the data, lets create a class for Jackknife sampling\n",
    "\n",
    "def mylen(x):\n",
    "    return len(x) if isinstance(x, np.ndarray) or isinstance(x, list) else 1\n",
    "\n",
    "class jackknife:\n",
    "\n",
    "    def __init__(self, list):\n",
    "        self.list=list\n",
    "        self.Lj=len(list)\n",
    "        self.Nj=self.Lj\n",
    "        Nt=mylen(self.list[0])\n",
    "        jackk=np.zeros((self.Nj-1,Nt))\n",
    "        self.jackkf=np.zeros((self.Nj,Nt))\n",
    "        for i in range(self.Nj):\n",
    "            jackk            = np.delete(self.list,i,axis=0)\n",
    "            self.jackkf[i]   = np.sum(jackk,axis=0)/(self.Nj-1)\n",
    "\n",
    "    #sample values: jackknife(original_ensemble).sample()=jackknife_ensemble\n",
    "    def sample(self):\n",
    "        return self.jackkf    \n",
    "\n",
    "    #jackknife covariance: jackknife(original_ensemble).fcov()=ensemble_stat(original_ensemble).rcov()\n",
    "    def fcov(self):\n",
    "        return np.cov(... TO_BE_FILLED     \n",
    "    \n",
    "    #augmented sample: jackknife(jackknife_ensemble).up()=original_ensemble\n",
    "    def up(self):\n",
    "        Lj=len(self.list)\n",
    "        mean=np.mean(self.list,axis=0)\n",
    "        ensem=self.list+(Lj)*(mean-self.list)\n",
    "        return ensem    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets code another class to compute means and covariances\n",
    "class ensemble_stat:\n",
    "\n",
    "    def __init__(self, list):\n",
    "        self.list=list\n",
    "\n",
    "    def mean(self):\n",
    "        mean=np.mean(self.list,axis=0)\n",
    "        return mean  \n",
    "\n",
    "    #reduced variance\n",
    "    def rcov(self):\n",
    "        Nj=len(self.list)\n",
    "        cov=np.cov(... TO_BE_FILLED\n",
    "        return cov    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the basic IMinuit penalty function class, lets modify it to include correlations\n",
    "\n",
    "class LeastSquares:\n",
    "    \"\"\"\n",
    "    Generic least-squares cost function with cov.\n",
    "    \"\"\"\n",
    "\n",
    "    errordef = Minuit.LEAST_SQUARES  # for Minuit to compute errors correctly\n",
    "\n",
    "    def __init__(self, model, x, y, incov): # IMPORTANT: We are reading the inverse of a covariance matrix\n",
    "        self.model = model  # model predicts y for given x\n",
    "        self.x = np.asarray(x)\n",
    "        self.y = np.asarray(y)\n",
    "        self.invcov = np.asarray(incov)\n",
    "\n",
    "    def __call__(self, *par):  # we must accept a variable number of model parameters\n",
    "        ym  = self.model(self.x, *par)\n",
    "        fun = np.dot(... TO_BE_FILLED\n",
    "\n",
    "        return fun\n",
    "        \n",
    "class BetterLeastSquares(LeastSquares):\n",
    "\n",
    "    def __init__(self, model, x, y, incov):\n",
    "        super().__init__(model, x, y, incov)\n",
    "        pars = describe(model, annotations=True)\n",
    "        model_args = iter(pars)\n",
    "        next(model_args)\n",
    "        _parameters = {k: pars[k] for k in model_args}\n",
    "\n",
    "\n",
    "class EvenBetterLeastSquares(BetterLeastSquares):\n",
    "    @property\n",
    "    def ndata(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's finish by definin a function as a sum of exponentials\n",
    "\n",
    "def exp_np(t,*pars):\n",
    "    total=0\n",
    "    mass=np.abs(pars[1])\n",
    "    total+=np.abs(pars[0])*np.exp(-mass*t)\n",
    "    for i in range(1,np.int_((len(pars)+1)/2)):\n",
    "        mass+=np.abs(pars[2*i+1])\n",
    "        total+=np.abs(pars[2*i])*np.exp(-mass*t)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets start with a simple plot and fit test to some specific data\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "\n",
    "\n",
    "jackk_C_r_t=jackknife(Gc).sample()                             # This is our main data sample for a fixed R     \n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "\n",
    "tini  =  TO_BE_FILLED    # Initial time fitted\n",
    "tfinal = TO_BE_FILLED    # Final time fitted\n",
    "\n",
    "data_t   = np.linspace(tini, tfinal, tfinal-tini+1)                               # Creating x axis values\n",
    "data_y   = ensemble_stat(...  TO_BE_FILLED [TO_BE_FILLED:TO_BE_FILLED]            # Obtaining the data averages over the Montecarlo samples\n",
    "data_cov = TO_BE_FILLED          # Obtaining the covariance matrix\n",
    "data_err = np.sqrt(np.diagonal(data_cov))[tini-1:tfinal]                              # This is the error from the covariance matrix\n",
    "data_incov=np.linalg.inv(data_cov)[TO_BE_FILLED,TO_BE_FILLED]\n",
    "\n",
    "\n",
    "funfit=exp_np                       # Model chosen to fit  C(t) for varying time t\n",
    "inipars=np.array([1.,1.])           # Initial parameters for the model to fit\n",
    "\n",
    "least_squares_np = EvenBetterLeastSquares(funfit, data_t, data_y, data_incov)\n",
    "m=Minuit(least_squares_np,*inipars)\n",
    "\n",
    "m.migrad(mcalls).migrad(mcalls).hesse(mcalls)\n",
    "\n",
    "chi2_total=m.fval\n",
    "\n",
    "data_t_plot=np.linspace(data_t[0],data_t[-1],1000)\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t_plot, funfit(data_t_plot, *m.values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you repeat the exercise, but without correlations?\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "\n",
    "totaltraj=int(len(data)/measured_T)\n",
    "\n",
    "jackk_C_r_t=jackknife(Gc).sample()                             # This is our main data sample for a fixed R     \n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "\n",
    "tini=3\n",
    "tfinal=16\n",
    "\n",
    "data_t   = np.linspace(tini, tfinal, tfinal-tini+1)                               # Creating x axis values\n",
    "data_y   = ensemble_stat(...  TO_BE_FILLED [TO_BE_FILLED:TO_BE_FILLED]            # Obtaining the data averages over the Montecarlo samples\n",
    "data_cov = TO_BE_FILLED          # Obtaining the covariance matrix\n",
    "data_cov = TO_BE_FILLED          # Diagonalize the matrix\n",
    "data_err = np.sqrt(np.diagonal(data_cov))[tini-1:tfinal]                              # This is the error from the covariance matrix\n",
    "data_incov=np.linalg.inv(data_cov)[TO_BE_FILLED,TO_BE_FILLED]\n",
    "\n",
    "\n",
    "funfit=exp_np                  # Model chosen to fit  C(t) for varying time t\n",
    "inipars=np.array([1.,1.])           # Initial parameters for the model to fit\n",
    "\n",
    "least_squares_np = EvenBetterLeastSquares(funfit, data_t, data_y, data_incov)\n",
    "m2=Minuit(least_squares_np,*inipars)\n",
    "\n",
    "m2.migrad(mcalls).migrad(mcalls).hesse(mcalls)\n",
    "\n",
    "data_t_plot=np.linspace(data_t[0],data_t[-1],1000)\n",
    "plt.errorbar(data_t, data_y, data_err, fmt=\"ok\", label=\"data\")\n",
    "plt.plot(data_t_plot, funfit(data_t_plot, *m.values), label=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare now both central values and errors for the ground state energy, are they compatible?\n",
    "\n",
    "print(TO_BE_FILLED, TO_BE_FILLED\n",
    "print(TO_BE_FILLED, TO_BE_FILLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now produce a Jackknife set of fits to data\n",
    "\n",
    "mcalls=5000\n",
    "mtol=0.0001\n",
    "\n",
    "jackk_C_r_t=jackknife(Gc).sample()                             # This is our main data sample for a fixed R     \n",
    "lt=len(Gc[0])\n",
    "dfin=min(lt,100)\n",
    "\n",
    "tini=3\n",
    "tfinal=16\n",
    "\n",
    "data_t   = np.linspace(tini, tfinal, tfinal-tini+1)                                     # Creating x axis values\n",
    "data_cov = TO_BE_FILLED          # Obtaining the covariance matrix\n",
    "data_err = np.sqrt(np.diagonal(data_cov))[tini-1:tfinal]                              # This is the error from the covariance matrix\n",
    "data_incov=np.linalg.inv(data_cov)[TO_BE_FILLED,TO_BE_FILLED]\n",
    "\n",
    "\n",
    "funfit=exp_np                  # Model chosen to fit  C(t) for varying time t\n",
    "inipars=np.array([1.,1.])           # Initial parameters for the model to fit\n",
    "\n",
    "\n",
    "E_0=np.zeros(totaltraj)\n",
    "chi2_jackk=np.zeros(totaltraj)\n",
    "for jackk TO_BE_FILLED\n",
    "    data_y   = TO_BE_FILLED[TO_BE_FILLED]                        # Obtaining the data averages over the Montecarlo samples\n",
    "\n",
    "    least_squares_np = EvenBetterLeastSquares(funfit, data_t, data_y, data_incov)\n",
    "    m=Minuit(least_squares_np,*inipars)\n",
    "\n",
    "    jackk_fit=m.migrad(mcalls).migrad(mcalls).hesse(mcalls)\n",
    "\n",
    "    E_0[jackk]        = TO_BE_FILLED\n",
    "    chi2_jackk[jackk] = jackk_fit.fval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's compare this value with the simple fit to data\n",
    "\n",
    "print(TO_BE_FILLED, TO_BE_FILLED\n",
    "      \n",
    "print(ensemble_stat(..., np.sqrt(... TO_BE_FILLED\n",
    "ensemble_stat(E_0).mean()\n",
    "\n",
    "np.sqrt(jackknife(jackknife(E_0).up()).fcov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA: Use the formula introduced in the lectures for the relation between the total chi2 and the Jackknife or Raw sample chi2's\n",
    "\n",
    "TO_BE_FILLED\n",
    "\n",
    "ensemble_stat(... TO_BE_FILLED-(tfinal-tini+1... TO_BE_FILLED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
